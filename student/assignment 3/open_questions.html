<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Open Questions</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="open_questions_files/libs/clipboard/clipboard.min.js"></script>
<script src="open_questions_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="open_questions_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="open_questions_files/libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="open_questions_files/libs/quarto-html/popper.min.js"></script>
<script src="open_questions_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="open_questions_files/libs/quarto-html/anchor.min.js"></script>
<link href="open_questions_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="open_questions_files/libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="open_questions_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="open_questions_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="open_questions_files/libs/bootstrap/bootstrap-d6a003b94517c951b2d65075d42fb01b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Open Questions</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="training-dynamics-mlp-vs-lstm" class="level2">
<h2 class="anchored" data-anchor-id="training-dynamics-mlp-vs-lstm">1) Training Dynamics (MLP vs LSTM)</h2>
<p>From the MLP curves, training improves steadily and validation improves too, but there is a small generalization gap by the end:</p>
<ul>
<li>Train loss keeps decreasing while val loss flattens, which is a classic mild overfitting pattern.</li>
<li>Train accuracy/F1 remain a bit higher than validation.</li>
</ul>
<p><img src="outputs/mlp/mlp_loss.png" class="img-fluid"> <img src="outputs/mlp/mlp_acc.png" class="img-fluid"> <img src="outputs/mlp/mlp_f1.png" class="img-fluid"></p>
<p>Some changes might reduce overfitting:</p>
<ul>
<li>Increase regularization: slightly higher dropout or stronger weight decay.</li>
<li>Add early stopping (stop when val macro-F1 stops improving).</li>
<li>Reduce hidden size a bit, smaller model = less capacity to overfit.</li>
</ul>
<p>The LSTM shows stronger overfitting:</p>
<ul>
<li>Training loss falls sharply to very low values, but validation loss stops improving and then increases noticeably after about mid training.</li>
<li>Train accuracy/macro-F1 rise very high, while validation levels off much lower.</li>
</ul>
<p>This indicates the LSTM is learning patterns that fit training well but do not generalize as well.</p>
<p><img src="outputs/lstm/lstm_loss.png" class="img-fluid"> <img src="outputs/lstm/lstm_acc.png" class="img-fluid"> <img src="outputs/lstm/lstm_f1.png" class="img-fluid"></p>
<p>Some change to address LSTM overfitting:</p>
<ul>
<li>Use early stopping, save best by val macro-F1 and stop once it hasn’t improved for a few epochs.</li>
<li>Increase dropout (especially on the classification head; optionally increase LSTM dropout by using <code>num_layers &gt; 1</code>).</li>
<li>Reduce model capacity (smaller hidden size, or remove bidirectionality if used).</li>
<li>Stronger weight decay / slightly smaller learning rate can also help.</li>
</ul>
<p>When useing the class weights, in the confusion matrices, both models learn to predict <em>neg</em> and <em>pos</em> rather than collapsing into mostly <em>neu</em>. The LSTM especially increases correct <em>pos</em> and <em>neg</em> predictions compared to the MLP.</p>
<p>Weighted loss can make updates “larger” for minority-class mistakes, which often causes the validation curves to look more jagged early on, but the final macro-F1 is usually better because the model is not ignoring minority classes.</p>
<p><img src="outputs/mlp/mlp_confusion_matrix.png" class="img-fluid"> <img src="outputs/lstm/lstm_confusion_matrix.png" class="img-fluid"></p>
</section>
<section id="model-performance-and-error-analysis-mlp-vs-lstm" class="level2">
<h2 class="anchored" data-anchor-id="model-performance-and-error-analysis-mlp-vs-lstm">2) Model Performance and Error Analysis (MLP vs LSTM)</h2>
<p>The LSTM generalized better than the MLP based on the test confusion matrices (and the metrics derived from them):</p>
<ul>
<li><p>MLP test accuracy: ( approx 0.715)<br>
</p></li>
<li><p>LSTM test accuracy: ( approx 0.751)</p></li>
<li><p>MLP test macro-F1 (from confusion matrix)</p></li>
<li><p>LSTM test macro-F1 (from confusion matrix)</p></li>
</ul>
<p>So the LSTM has higher test accuracy and higher test macro-F1, which is stronger evidence of better generalization (macro-F1 is especially important for imbalanced classes).</p>
<p><img src="outputs/mlp/mlp_confusion_matrix.png" class="img-fluid"><br>
<img src="outputs/lstm/lstm_confusion_matrix.png" class="img-fluid"></p>
<p>By raw count (most frequent overall): Neutral (neu) is misclassified the most in both models because it is the largest class and sits “between” negative and positive:</p>
<ul>
<li>MLP: neu misclassified 97 times<br>
</li>
<li>LSTM: neu misclassified 94 times</li>
</ul>
<p>By error rate : Positive (pos) is misclassified the most:</p>
<ul>
<li>MLP pos error rate: ( approx 41.7% )</li>
<li>LSTM pos error rate: ( approx 32.4% )</li>
</ul>
<p>Likely reason for this to happen: Neutral is semantically close to both neg and pos, so many sentences have subtle wording where sentiment is weak/implicit → the model confuses “slightly positive/negative” with neutral. And financial text is often phrased cautiously, with limited emotional words. Small cues like “expected”, “may”, “forecast”, “pressure”, “improve” can flip sentiment but are easy to miss.</p>
</section>
<section id="cross-model-comparison-mlp-rnn-lstm-gru-bert-gpt" class="level2">
<h2 class="anchored" data-anchor-id="cross-model-comparison-mlp-rnn-lstm-gru-bert-gpt">3) Cross-Model Comparison (MLP, RNN, LSTM, GRU, BERT, GPT)</h2>
<p>The MLP uses mean-pooled FastText, which collapses each sentence into a single 300-d vector by averaging word vectors. This limits it because there is no word order, like sentence “profits fell despite strong guidance” vs “strong guidance despite profits fell” can become very similar after averaging. And ther is no phrase structure, negation/modifiers like “not”, “barely”, “despite”, “however” get diluted in the average. In addition, there is no token-level emphasis, one crucial sentiment word can be washed out by many neutral words.</p>
<p>The LSTM is a sequence mode: it processes a fixed-length sequence in order, and the final hidden state summarizes the sentence. So the advantages compare to MLP are</p>
<ul>
<li>Models word order.</li>
<li>Captures patterns like negation, contrast, and clause-level shifts.</li>
<li>Uses context: the meaning of a word can depend on surrounding words.</li>
</ul>
<p>Did fine-tuned LLMs (BERT/GPT) outperform classical baselines?</p>
<p>Yes. BERT and GPT outperform the FastText+neural baselines because they start from pretrained contextual representations: - Pretraining on massive corpora teaches general language patterns, syntax, semantics, and domain-relevant associations. - Their embeddings are contextual: the representation of “rise”, “cut”, “beat”, “miss” changes based on surrounding words. - Fine-tuning adapts those rich features to sentiment classification with relatively little labeled data.</p>
<p><strong>BERT</strong><br>
<img src="outputs/bert/bert_f1_learning_curves.png" class="img-fluid"><br>
<img src="outputs/bert/bert_confusion_matrix.png" class="img-fluid"></p>
<p><strong>GPT</strong><br>
<img src="outputs/gpt/gpt_f1_learning_curves.png" class="img-fluid"><br>
<img src="outputs/gpt/gpt_confusion_matrix.png" class="img-fluid"></p>
<p>Rank all six models</p>
<p>Using the test confusion matrices, the test macro-F1 ranking is:</p>
<ol type="1">
<li><strong>BERT</strong></li>
<li><strong>GPT</strong></li>
<li><strong>LSTM</strong></li>
<li><strong>GRU</strong><br>
</li>
<li><strong>MLP</strong></li>
</ol>
<p>Why this ranking makes sense: - BERT/GPT : pretrained contextual features + transformer attention → strongest generalization and best handling of subtle sentiment cues. - LSTM/GRU: sequence modeling captures order/negation/phrases; GRU and LSTM are similar, with small differences depending on hyperparams and regularization. - MLP: mean pooling removes order and weakens compositional meaning → struggles more on nuanced examples. - Vanilla RNN: weaker at long-range dependencies (vanishing gradients) compared to gated models (LSTM/GRU), so it tends to confuse sentiment when important cues occur later in the sentence.</p>
</section>
<section id="ai-use-disclosure" class="level2">
<h2 class="anchored" data-anchor-id="ai-use-disclosure">AI Use Disclosure</h2>
<ul>
<li><strong>Tool(s) used:</strong> Chatgpt</li>
<li><strong>How you used them:</strong> I give it the code I wrote and ask if it is correct, I also asked it of the errors I got and the suggestion to fix them. And I used it to refine my answer to the open queation</li>
<li><strong>What you verified yourself:</strong> I checked the output to see whether it is reasonable</li>
</ul>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>